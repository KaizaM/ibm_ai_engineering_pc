{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Transformers with Keras\n",
    "\n",
    "Estimated time needed **45** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_cpu==2.17.1\n",
      "  Downloading tensorflow_cpu-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow_cpu==2.17.1) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow_cpu==2.17.1) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow_cpu==2.17.1) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow_cpu==2.17.1) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow_cpu==2.17.1) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading keras-3.13.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow_cpu==2.17.1)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow_cpu==2.17.1) (0.45.1)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow_cpu==2.17.1)\n",
      "  Downloading rich-14.3.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow_cpu==2.17.1)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow_cpu==2.17.1)\n",
      "  Downloading optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1)\n",
      "  Downloading markdown-3.10.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1)\n",
      "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow_cpu==2.17.1)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow_cpu==2.17.1) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow_cpu==2.17.1)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow_cpu-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (221.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.13.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading markdown-3.10.1-py3-none-any.whl (107 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading rich-14.3.1-py3-none-any.whl (309 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow_cpu\n",
      "Successfully installed absl-py-2.4.0 astunparse-1.6.3 flatbuffers-25.12.19 gast-0.7.0 google-pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.13.1 libclang-18.1.1 markdown-3.10.1 markdown-it-py-4.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.1.0 numpy-1.26.4 opt-einsum-3.4.0 optree-0.18.0 protobuf-4.25.8 rich-14.3.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow_cpu-2.17.1 termcolor-3.3.0 werkzeug-3.1.5 wrapt-2.0.1\n",
      "Collecting matplotlib==3.9.2\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.2)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.2)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.2)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.2)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.2)\n",
      "  Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.2)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.9.2 pillow-12.1.0 pyparsing-3.3.2\n",
      "==== All required libraries are installed =====\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_cpu==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [3, 4, 5], [1, 6, 7, 8, 9], [10, 11, 12, 13], [1, 14, 15]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "attention = AdditiveAttention()\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 2.8343\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.3200 - loss: 2.8028\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.3200 - loss: 2.7704\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.3200 - loss: 2.7339\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3200 - loss: 2.6903\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.2800 - loss: 2.6360\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.2800 - loss: 2.5660\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.2800 - loss: 2.4747\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2800 - loss: 2.3575\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2400 - loss: 2.2211\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.2400 - loss: 2.1041\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2400 - loss: 2.0641\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2400 - loss: 2.0528\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.2800 - loss: 1.9939\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.3200 - loss: 1.9092\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.3600 - loss: 1.8455\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4800 - loss: 1.8128\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5200 - loss: 1.7719\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5600 - loss: 1.7113\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7200 - loss: 1.6429\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.6800 - loss: 1.5766\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6400 - loss: 1.5155\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5600 - loss: 1.4583\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5200 - loss: 1.4020\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.5200 - loss: 1.3422\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.5200 - loss: 1.2747\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.6000 - loss: 1.1987\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.6400 - loss: 1.1181\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6400 - loss: 1.0391\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7600 - loss: 0.9663\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.8000 - loss: 0.9008\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8000 - loss: 0.8428\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8800 - loss: 0.7879\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8800 - loss: 0.7320\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9200 - loss: 0.6768\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9200 - loss: 0.6230\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9200 - loss: 0.5704\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.5226\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.4794\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.4372\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.3991\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.3638\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.3317\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.3050\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.2777\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.2520\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.2299\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.2097\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1916\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1737\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1579\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.1432\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.1297\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.1184\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.1080\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0983\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0889\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0814\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0744\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0681\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0621\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.0567\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0519\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0475\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0438\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0405\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0375\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0348\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0322\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0299\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0279\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0261\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0245\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0230\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0216\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0204\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0193\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0164\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0155\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0148\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0142\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0135\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0124\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0119\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0114\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0110\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0106\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0102\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0098\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0081\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome, now you have succesfully trained a transformers model.\n",
    "### Now let's try some practice excercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0800 - loss: 2.8323\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.3600 - loss: 2.8003\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.3200 - loss: 2.7665\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.3200 - loss: 2.7272\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3200 - loss: 2.6785\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.3200 - loss: 2.6153\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2800 - loss: 2.5313\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2800 - loss: 2.4199\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.2800 - loss: 2.2811\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2800 - loss: 2.1416\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2800 - loss: 2.0679\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2800 - loss: 2.0747\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2800 - loss: 2.0564\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2800 - loss: 1.9924\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.3600 - loss: 1.9244\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.4800 - loss: 1.8729\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.4800 - loss: 1.8256\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.4800 - loss: 1.7757\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5600 - loss: 1.7244\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.5600 - loss: 1.6729\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.5600 - loss: 1.6211\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.5200 - loss: 1.5688\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.4800 - loss: 1.5161\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4800 - loss: 1.4625\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.4400 - loss: 1.4059\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.4400 - loss: 1.3431\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5600 - loss: 1.2719\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.5600 - loss: 1.1946\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.6000 - loss: 1.1181\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6800 - loss: 1.0485\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7600 - loss: 0.9855\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7200 - loss: 0.9228\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7600 - loss: 0.8567\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8000 - loss: 0.7905\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8000 - loss: 0.7275\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9200 - loss: 0.6668\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.9600 - loss: 0.6097\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9600 - loss: 0.5601\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.9600 - loss: 0.5170\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.4779\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.4401\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.4011\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.3659\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.3381\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.3142\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.2890\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.2630\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.2379\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.2168\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.1996\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1838\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.1677\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.1518\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1383\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.1271\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.1167\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1068\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0973\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0887\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0811\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0742\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0683\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0628\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0577\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0529\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0487\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0450\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0417\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0387\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0360\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0335\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0313\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0274\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0257\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0242\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0228\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0215\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0203\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0192\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0165\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0157\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0150\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0143\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0137\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0131\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0126\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0121\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0117\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0108\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0098\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0086\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your answer here\n",
    "\n",
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "attention = AdditiveAttention()\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Step 6: Train the Model\n",
    "history_heuniform_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_heuniform_adam.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "\n",
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,), name=\"decoder_inputs\")\n",
    "decoder_embedding = Embedding(output_vocab_size, 256, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "#Attention Mechanism\n",
    "attention = AdditiveAttention(name=\"attention_layer\")\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Concatenate context with decoder outputs\n",
    "decoder_concat = Concatenate(axis=-1, name=\"concat_layer\")([decoder_outputs, attention_output])\n",
    "\n",
    "# Final Dense Layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax', name=\"output_dense\")\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0083\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Write your answer here\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()\n",
    "# Step 6: Train the Model\n",
    "history_grad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_heuniform_adam.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.plot(history_grad.history['loss'], label=\"grad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "-->\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "0a2f1c23451e90dafa6342776b11efcb1308959b2f77af45d77f72bbadb754ca"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
